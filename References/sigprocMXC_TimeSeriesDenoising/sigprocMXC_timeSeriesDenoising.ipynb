{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.signal\n",
    "from scipy import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# VIDEO: Mean-smooth a time series\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create signal\n",
    "srate = 1000 # Hz\n",
    "time  = np.arange(0,3,1/srate)\n",
    "n     = len(time)\n",
    "p     = 15 # poles for random interpolation\n",
    "\n",
    "# noise level, measured in standard deviations\n",
    "noiseamp = 5\n",
    "\n",
    "# amplitude modulator and noise level\n",
    "ampl   = np.interp(np.linspace(0,p,n),np.arange(0,p),np.random.rand(p)*30)\n",
    "noise  = noiseamp * np.random.randn(n)\n",
    "signal = ampl + noise\n",
    "\n",
    "# initialize filtered signal vector\n",
    "filtsig = np.zeros(n)\n",
    "\n",
    "# implement the running mean filter\n",
    "k = 20 # filter window is actually k*2+1\n",
    "for i in range(k,n-k):\n",
    "    # each point is the average of k surrounding points\n",
    "    filtsig[i] = np.mean(signal[i-k:i+k])\n",
    "\n",
    "# compute window size in ms\n",
    "windowsize = 1000*(k*2+1) / srate\n",
    "\n",
    "\n",
    "# plot the noisy and filtered signals\n",
    "plt.plot(time,signal,label='orig')\n",
    "plt.plot(time,filtsig,label='filtered')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Time (sec.)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Running-mean filter with a k=%d-ms filter' %windowsize)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# VIDEO: Gaussian-smooth a time series\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create signal\n",
    "srate = 1000 # Hz\n",
    "time  = np.arange(0,3,1/srate)\n",
    "n     = len(time)\n",
    "p     = 15 # poles for random interpolation\n",
    "\n",
    "# noise level, measured in standard deviations\n",
    "noiseamp = 5\n",
    "\n",
    "# amplitude modulator and noise level\n",
    "ampl   = np.interp(linspace(1,p,n),np.arange(0,p),np.random.rand(p)*30)\n",
    "noise  = noiseamp * np.random.randn(n)\n",
    "signal = ampl + noise\n",
    "\n",
    "\n",
    "\n",
    "## create Gaussian kernel\n",
    "# full-width half-maximum: the key Gaussian parameter\n",
    "fwhm = 25 # in ms\n",
    "\n",
    "# normalized time vector in ms\n",
    "k = 100\n",
    "gtime = 1000*np.arange(-k,k)/srate\n",
    "\n",
    "# create Gaussian window\n",
    "gauswin = np.exp( -(4*np.log(2)*gtime**2) / fwhm**2 )\n",
    "\n",
    "# compute empirical FWHM\n",
    "pstPeakHalf = k + np.argmin( (gauswin[k:]-.5)**2 )\n",
    "prePeakHalf = np.argmin( (gauswin-.5)**2 )\n",
    "\n",
    "empFWHM = gtime[pstPeakHalf] - gtime[prePeakHalf]\n",
    "\n",
    "# show the Gaussian\n",
    "plt.plot(gtime,gauswin,'ko-')\n",
    "plt.plot([gtime[prePeakHalf],gtime[pstPeakHalf]],[gauswin[prePeakHalf],gauswin[pstPeakHalf]],'m')\n",
    "\n",
    "# then normalize Gaussian to unit energy\n",
    "gauswin = gauswin / np.sum(gauswin)\n",
    "# title([ 'Gaussian kernel with requeted FWHM ' num2str(fwhm) ' ms (' num2str(empFWHM) ' ms achieved)' ])\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Gain')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement the filter\n",
    "\n",
    "# initialize filtered signal vector\n",
    "filtsigG = copy.deepcopy(signal)\n",
    "\n",
    "# # implement the running mean filter\n",
    "for i in range(k+1,n-k):\n",
    "    # each point is the weighted average of k surrounding points\n",
    "    filtsigG[i] = np.sum( signal[i-k:i+k]*gauswin )\n",
    "\n",
    "# plot\n",
    "plt.plot(time,signal,'r',label='Original')\n",
    "plt.plot(time,filtsigG,'k',label='Gaussian-filtered')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('amp. (a.u.)')\n",
    "plt.legend()\n",
    "plt.title('Gaussian smoothing filter')\n",
    "\n",
    "## for comparison, plot mean smoothing filter\n",
    "\n",
    "# initialize filtered signal vector\n",
    "filtsigMean = copy.deepcopy(signal)\n",
    "\n",
    "# implement the running mean filter\n",
    "# note: using mk instead of k to avoid confusion with k above\n",
    "mk = 20 # filter window is actually mk*2+1\n",
    "for i in range(mk+1,n-mk-1):\n",
    "    # each point is the average of k surrounding points\n",
    "    filtsigMean[i] = mean(signal[i-mk:i+mk])\n",
    "\n",
    "plt.plot(time,filtsigMean,'b',label='Running mean')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# VIDEO: Gaussian-smooth a spike time series\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate time series of random spikes\n",
    "\n",
    "# number of spikes\n",
    "n = 300\n",
    "\n",
    "# inter-spike intervals (exponential distribution for bursts)\n",
    "isi = np.round(np.exp( np.random.randn(n) )*10)\n",
    "\n",
    "# generate spike time series\n",
    "spikets = np.zeros(int(sum(isi)))\n",
    "\n",
    "for i in range(0,n):\n",
    "    spikets[ int(np.sum(isi[0:i])) ] = 1\n",
    "\n",
    "\n",
    "# plot\n",
    "plt.plot(spikets)\n",
    "plt.xlabel('Time (a.u.)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create and implement Gaussian window\n",
    "\n",
    "# full-width half-maximum: the key Gaussian parameter\n",
    "fwhm = 25 # in points\n",
    "\n",
    "# normalized time vector in ms\n",
    "k = 100;\n",
    "gtime = np.arange(-k,k)\n",
    "\n",
    "# create Gaussian window\n",
    "gauswin = np.exp( -(4*log(2)*gtime**2) / fwhm**2 )\n",
    "gauswin = gauswin / np.sum(gauswin)\n",
    "\n",
    "# initialize filtered signal vector\n",
    "filtsigG = np.zeros(len(spikets))\n",
    "\n",
    "# implement the weighted running mean filter\n",
    "for i in range(k+1,len(spikets)-k):\n",
    "    filtsigG[i] = np.sum( spikets[i-k:i+k]*gauswin )\n",
    "\n",
    "\n",
    "# plot the filtered signal (spike probability density)\n",
    "plt.plot(spikets,'b',label='spikes')\n",
    "plt.plot(filtsigG,'r',label='spike p.d.')\n",
    "plt.legend()\n",
    "plt.title('Spikes and spike probability density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# VIDEO: Denoising via TKEO\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "emgdata = sio.loadmat('emg4TKEO.mat')\n",
    "\n",
    "# extract needed variables\n",
    "emgtime = emgdata['emgtime'][0]\n",
    "emg  = emgdata['emg'][0]\n",
    "\n",
    "# initialize filtered signal\n",
    "emgf = copy.deepcopy(emg)\n",
    "\n",
    "# the loop version for interpretability\n",
    "for i in range(1,len(emgf)-1):\n",
    "    emgf[i] = emg[i]**2 - emg[i-1]*emg[i+1]\n",
    "\n",
    "# the vectorized version for speed and elegance\n",
    "emgf2 = copy.deepcopy(emg)\n",
    "emgf2[1:-1] = emg[1:-1]**2 - emg[0:-2]*emg[2:]\n",
    "\n",
    "## convert both signals to zscore\n",
    "\n",
    "# find timepoint zero\n",
    "time0 = np.argmin(emgtime**2)\n",
    "\n",
    "# convert original EMG to z-score from time-zero\n",
    "emgZ = (emg-np.mean(emg[0:time0])) / np.std(emg[0:time0])\n",
    "\n",
    "# same for filtered EMG energy\n",
    "emgZf = (emgf-np.mean(emgf[0:time0])) / std(emgf[0:time0])\n",
    "\n",
    "\n",
    "## plot\n",
    "# plot \"raw\" (normalized to max.1)\n",
    "plt.plot(emgtime,emg/np.max(emg),'b',label='EMG')\n",
    "plt.plot(emgtime,emgf/np.max(emgf),'m',label='TKEO energy')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Amplitude or energy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plot zscored\n",
    "plt.plot(emgtime,emgZ,'b',label='EMG')\n",
    "plt.plot(emgtime,emgZf,'m',label='TKEO energy')\n",
    "\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Zscore relative to pre-stimulus')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "VIDEO: Median filter to remove spike noise\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create signal\n",
    "n = 2000\n",
    "signal = np.cumsum(np.random.randn(n))\n",
    "\n",
    "\n",
    "# proportion of time points to replace with noise\n",
    "propnoise = .05\n",
    "\n",
    "# find noise points\n",
    "noisepnts = np.random.permutation(n)\n",
    "noisepnts = noisepnts[0:int(n*propnoise)]\n",
    "\n",
    "# generate signal and replace points with noise\n",
    "signal[noisepnts] = 50+np.random.rand(len(noisepnts))*100\n",
    "\n",
    "\n",
    "# use hist to pick threshold\n",
    "plt.hist(signal,100)\n",
    "plt.show()\n",
    "\n",
    "# visual-picked threshold\n",
    "threshold = 40\n",
    "\n",
    "\n",
    "# find data values above the threshold\n",
    "suprathresh = np.where( signal>threshold )[0]\n",
    "\n",
    "# initialize filtered signal\n",
    "filtsig = copy.deepcopy(signal)\n",
    "\n",
    "# loop through suprathreshold points and set to median of k\n",
    "k = 20 # actual window is k*2+1\n",
    "for ti in range(len(suprathresh)):\n",
    "    \n",
    "    # lower and upper bounds\n",
    "    lowbnd = np.max((0,suprathresh[ti]-k))\n",
    "    uppbnd = np.min((suprathresh[ti]+k,n+1))\n",
    "    \n",
    "    # compute median of surrounding points\n",
    "    filtsig[suprathresh[ti]] = np.median(signal[lowbnd:uppbnd])\n",
    "\n",
    "# plot\n",
    "plt.plot(range(0,n),signal, range(0,n),filtsig)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# VIDEO: Remove linear trend\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create signal with linear trend imposed\n",
    "n = 2000\n",
    "signal = np.cumsum(np.random.randn(n)) + np.linspace(-30,30,n)\n",
    "\n",
    "# linear detrending\n",
    "detsignal = scipy.signal.detrend(signal)\n",
    "\n",
    "# get means\n",
    "omean = np.mean(signal) # original mean\n",
    "dmean = np.mean(detsignal) # detrended mean\n",
    "\n",
    "# plot signal and detrended signal\n",
    "plt.plot(range(0,n),signal,label='Original, mean=%d' %omean)\n",
    "plt.plot(range(0,n),detsignal,label='Detrended, mean=%d' %dmean)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# VIDEO: Remove nonlinear trend with polynomials\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## polynomial intuition\n",
    "\n",
    "order = 2\n",
    "x = np.linspace(-15,15,100)\n",
    "\n",
    "y = np.zeros(len(x))\n",
    "\n",
    "for i in range(order+1):\n",
    "    y = y + np.random.randn(1)*x**i\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.title('Order-%d polynomial' %order)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate signal with slow polynomial artifact\n",
    "\n",
    "n = 10000\n",
    "t = range(n)\n",
    "k = 10 # number of poles for random amplitudes\n",
    "\n",
    "slowdrift = np.interp(np.linspace(1,k,n),np.arange(0,k),100*np.random.randn(k))\n",
    "signal = slowdrift + 20*np.random.randn(n)\n",
    "\n",
    "# plot\n",
    "plt.plot(t,signal)\n",
    "plt.xlabel('Time (a.u.)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit a 3-order polynomial\n",
    "\n",
    "# polynomial fit (returns coefficients)\n",
    "p = polyfit(t,signal,3)\n",
    "\n",
    "# predicted data is evaluation of polynomial\n",
    "yHat = polyval(p,t)\n",
    "\n",
    "# compute residual (the cleaned signal)\n",
    "residual = signal - yHat\n",
    "\n",
    "\n",
    "# now plot the fit (the function that will be removed)\n",
    "plt.plot(t,signal,'b',label='Original')\n",
    "plt.plot(t,yHat,'r',label='Polyfit')\n",
    "plt.plot(t,residual,'k',label='Filtered signal')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bayes information criterion to find optimal order\n",
    "\n",
    "# possible orders\n",
    "orders = range(5,40)\n",
    "\n",
    "# sum of squared errors (sse is reserved!)\n",
    "sse1 = np.zeros(len(orders))\n",
    "\n",
    "# loop through orders\n",
    "for ri in range(len(orders)):\n",
    "    \n",
    "    # compute polynomial (fitting time series)\n",
    "    yHat = np.polyval(polyfit(t,signal,orders[ri]),t)\n",
    "    \n",
    "    # compute fit of model to data (sum of squared errors)\n",
    "    sse1[ri] = np.sum( (yHat-signal)**2 )/n\n",
    "\n",
    "\n",
    "# Bayes information criterion\n",
    "bic = n*np.log(sse1) + orders*np.log(n)\n",
    "\n",
    "# best parameter has lowest BIC\n",
    "bestP = min(bic)\n",
    "idx = np.argmin(bic)\n",
    "\n",
    "# plot the BIC\n",
    "plt.plot(orders,bic,'ks-')\n",
    "plt.plot(orders[idx],bestP,'ro')\n",
    "plt.xlabel('Polynomial order')\n",
    "plt.ylabel('Bayes information criterion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now repeat filter for best (smallest) BIC\n",
    "\n",
    "# polynomial fit\n",
    "polycoefs = polyfit(t,signal,orders[idx])\n",
    "\n",
    "# estimated data based on the coefficients\n",
    "yHat = polyval(polycoefs,t)\n",
    "\n",
    "# filtered signal is residual\n",
    "filtsig = signal - yHat\n",
    "\n",
    "\n",
    "## plotting\n",
    "plt.plot(t,signal,'b',label='Original')\n",
    "plt.plot(t,yHat,'r',label='Polynomial fit')\n",
    "plt.plot(t,filtsig,'k',label='Filtered')\n",
    "\n",
    "plt.xlabel('Time (a.u.)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# VIDEO: Averaging multiple repetitions (time-synchronous averaging)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simulate data\n",
    "\n",
    "# create event (derivative of Gaussian)\n",
    "k = 100 # duration of event in time points\n",
    "event = np.diff(np.exp( -np.linspace(-2,2,k+1)**2 ))\n",
    "event = event/np.max(event) # normalize to max=1\n",
    "\n",
    "# event onset times\n",
    "Nevents = 30\n",
    "onsettimes = np.random.permutation(10000-k)\n",
    "onsettimes = onsettimes[0:Nevents]\n",
    "\n",
    "# put event into data\n",
    "data = np.zeros(10000)\n",
    "for ei in range(Nevents):\n",
    "    data[onsettimes[ei]:onsettimes[ei]+k] = event\n",
    "\n",
    "# add noise\n",
    "data = data + .5*np.random.randn(len(data))\n",
    "\n",
    "# plot data\n",
    "plt.subplot(211)\n",
    "plt.plot(data)\n",
    "\n",
    "# plot one event\n",
    "plt.subplot(212)\n",
    "plt.plot(range(k), data[onsettimes[3]:onsettimes[3]+k])\n",
    "plt.plot(range(k), event)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract all events into a matrix\n",
    "\n",
    "datamatrix = np.zeros((Nevents,k))\n",
    "\n",
    "for ei in range(Nevents):\n",
    "    datamatrix[ei,:] = data[onsettimes[ei]:onsettimes[ei]+k]\n",
    "\n",
    "plt.imshow(datamatrix)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Event number')\n",
    "plt.title('All events')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(0,k),np.mean(datamatrix,axis=0),label='Averaged')\n",
    "plt.plot(range(0,k),event,label='Ground-truth')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.title('Average events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# VIDEO: Remove artifact via least-squares template-matching\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "matdat = sio.loadmat('templateProjection.mat')\n",
    "EEGdat = matdat['EEGdat']\n",
    "eyedat = matdat['eyedat']\n",
    "timevec = matdat['timevec'][0]\n",
    "MN = np.shape(EEGdat) # matrix sizes\n",
    "\n",
    "# initialize residual data\n",
    "resdat = zeros(np.shape(EEGdat))\n",
    "\n",
    "\n",
    "# loop over trials\n",
    "for triali in range(MN[1]):\n",
    "    \n",
    "    # build the least-squares model as intercept and EOG from this trial\n",
    "    X = np.column_stack((np.ones(MN[0]),eyedat[:,triali]))\n",
    "    \n",
    "    # compute regression coefficients for EEG channel\n",
    "    b = np.linalg.solve(np.matrix.transpose(X)@X,np.matrix.transpose(X)@EEGdat[:,triali])\n",
    "    \n",
    "    # predicted data\n",
    "    yHat = X@b\n",
    "    \n",
    "    # new data are the residuals after projecting out the best EKG fit\n",
    "    resdat[:,triali] = EEGdat[:,triali] - yHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting\n",
    "\n",
    "# trial averages\n",
    "plt.plot(timevec,np.mean(eyedat,axis=1),label='EOG')\n",
    "plt.plot(timevec,np.mean(EEGdat,axis=1),label='EEG')\n",
    "plt.plot(timevec,np.mean(resdat,1),label='Residual')\n",
    "\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show all trials in a map\n",
    "clim = [-1,1]*20\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(eyedat.T)\n",
    "plt.title('EOG')\n",
    "\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(EEGdat.T)\n",
    "plt.title('EOG')\n",
    "\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(resdat.T)\n",
    "plt.title('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
